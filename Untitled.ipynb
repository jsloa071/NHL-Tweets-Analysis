{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "#data collection packages\n",
    "import csv\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "from twitterscraper import query_tweets\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# data processing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "# data vis packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "The data I want:\n",
    "<ul>\n",
    "    <li>A list of current NHL team handles</li>\n",
    "    <li>All tweets for teams in a given time period (e.g. since the beginning of the season; 2018 playoffs)</li>\n",
    "    <li>Team rankings at a given time period</li>\n",
    "    <li>Historical dates and outcomes of games for a given time period, for a given team(s)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_datafile = 'data/tweets.csv' # for storing raw tweet data\n",
    "polarity_datafile = 'data/tweets_polarities.csv' # for storing cleaned data with sentiment polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_handles():\n",
    "    chromedriver = os.environ['CHROMEDRIVER']\n",
    "    if not Path(chromedriver).exists():\n",
    "        logging.info('Installing Chrome driver')\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    \n",
    "    print('Grabbing team handles from Twitter')\n",
    "\n",
    "    browser = webdriver.Chrome(chromedriver)\n",
    "    url = 'https://twitter.com/NHL/lists/nhl-team-accounts/members?lang=en'\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    for i in range(5):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    users = browser.find_elements_by_class_name('username')\n",
    "\n",
    "    team_handles = []\n",
    "    for user in users:\n",
    "        if user.text and user.text not in team_handles:\n",
    "            team_handles.append(user.text)\n",
    "            print('Added team handle: ', user.text)\n",
    "    print('Successfully found ', len(team_handles), ' handles!')\n",
    "    return team_handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabbing team handles from Twitter\n",
      "Added team handle:  @NHLSeattle_\n",
      "Added team handle:  @GoldenKnights\n",
      "Added team handle:  @NHLJets\n",
      "Added team handle:  @MapleLeafs\n",
      "Added team handle:  @NHL\n",
      "Added team handle:  @NHLBruins\n",
      "Added team handle:  @Senators\n",
      "Added team handle:  @NJDevils\n",
      "Added team handle:  @FlaPanthers\n",
      "Added team handle:  @DallasStars\n",
      "Added team handle:  @PredsNHL\n",
      "Added team handle:  @TBLightning\n",
      "Added team handle:  @SanJoseSharks\n",
      "Added team handle:  @NHLFlames\n",
      "Added team handle:  @Avalanche\n",
      "Added team handle:  @BlueJacketsNHL\n",
      "Added team handle:  @StLouisBlues\n",
      "Added team handle:  @BuffaloSabres\n",
      "Added team handle:  @NYRangers\n",
      "Added team handle:  @ArizonaCoyotes\n",
      "Added team handle:  @AnaheimDucks\n",
      "Added team handle:  @CanadiensMTL\n",
      "Added team handle:  @NHLCanes\n",
      "Added team handle:  @NHLFlyers\n",
      "Added team handle:  @LAKings\n",
      "Added team handle:  @mnwild\n",
      "Added team handle:  @Canucks\n",
      "Added team handle:  @DetroitRedWings\n",
      "Added team handle:  @NYIslanders\n",
      "Added team handle:  @EdmontonOilers\n",
      "Added team handle:  @penguins\n",
      "Added team handle:  @Capitals\n",
      "Added team handle:  @NHLBlackhawks\n",
      "Successfully found  33  handles!\n"
     ]
    }
   ],
   "source": [
    "team_handles = get_team_handles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tweets(begindate=dt.date(2018, 10, 3), enddate=dt.date.today(), filepath=tweets_datafile, handles=team_handles):\n",
    "    logger = logging.getLogger('twitterscraper')\n",
    "    logger.disabled = True\n",
    "    \n",
    "    r = requests.get('https://twitter.com/NHL/lists/nhl-team-accounts/members?lang=en')\n",
    "    with open(filepath, 'w') as csv_file:\n",
    "        fieldnames = ['user', 'team', 'timestamp', 'likes', 'replies', 'retweets', 'text']\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        csv_writer.writeheader()\n",
    "        for team_handle in handles:\n",
    "            print(team_handle)\n",
    "            team_tweets = query_tweets(team_handle, limit=10000, begindate=begindate, enddate=enddate)\n",
    "            print(\"found \", len(team_tweets), \" tweets for\", team_handle)\n",
    "            for tweet in team_tweets:\n",
    "                csv_writer.writerow({'user': tweet.user,\n",
    "                                     'team': team_handle,\n",
    "                                     'timestamp': tweet.timestamp,\n",
    "                                     'likes': tweet.likes,\n",
    "                                     'replies': tweet.replies,\n",
    "                                     'retweets': tweet.retweets,\n",
    "                                     'text': tweet.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity - taking the maximum sentence polarity in a tweet\n",
    "# TODO: improve by building own classifier. \n",
    "def create_polarities(filepath=tweets_datafile, polarity_filepath=polarity_datafile):\n",
    "    print('Adding polarities...')\n",
    "    dataframe = pd.read_csv(filepath)\n",
    "    size = len(dataframe.index)\n",
    "    dataframe['polarity'] = np.nan\n",
    "    dataframe['positive'] = 0\n",
    "    dataframe['negative'] = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        sentence = row['text']\n",
    "        if isinstance(sentence, str):\n",
    "            polarity = TextBlob(sentence).sentiment.polarity\n",
    "            dataframe.at[index, 'polarity'] = polarity\n",
    "            if polarity > 0:\n",
    "                dataframe.at[index, 'positive'] = 1\n",
    "            elif polarity < 0:\n",
    "                dataframe.at[index, 'negative'] = 1\n",
    "    dataframe.to_csv(polarity_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(polarity_datafile).exists():\n",
    "    if not Path(tweets_datafile).exists():\n",
    "        collect_data()\n",
    "    create_polarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = pd.read_csv(polarity_datafile, parse_dates = ['timestamp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    return df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_tweets = preprocess(tweets_data[tweets_data['team'] != '@NHL'])\n",
    "team_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use API to get rankings\n",
    "current_rankings = {\n",
    "    '@TBLightning': 1,\n",
    "    '@NHLFlames': 2,\n",
    "    '@SanJoseSharks': 3,\n",
    "    '@MapleLeafs': 4,\n",
    "    '@NHLJets': 5,\n",
    "    '@NYIslanders': 6,\n",
    "    '@PredsNHL': 7,\n",
    "    '@CanadiensMTL': 8,\n",
    "    '@NHLBruins': 9,\n",
    "    '@Capitals': 10,\n",
    "    '@GoldenKnights': 11,\n",
    "    '@BlueJacketsNHL': 12,\n",
    "    '@penguins': 13,\n",
    "    '@NHLCanes': 14,\n",
    "    '@BuffaloSabres': 15,\n",
    "    '@DallasStars': 16,\n",
    "    '@mnwild': 17,\n",
    "    '@StLouisBlues': 18,\n",
    "    '@NHLFlyers': 19,\n",
    "    '@Canucks': 20,\n",
    "    '@FlaPanthers': 21,\n",
    "    '@Avalanche': 22,\n",
    "    '@NYRangers': 23,\n",
    "    '@ArizonaCoyotes': 24,\n",
    "    '@NHLBlackhawks': 25,\n",
    "    '@EdmontonOilers': 26,\n",
    "    '@LAKings': 27,\n",
    "    '@AnaheimDucks': 28,\n",
    "    '@DetroitRedWings': 29,\n",
    "    '@NJDevils': 30,\n",
    "    '@Senators': 31\n",
    "}\n",
    "\n",
    "playoff_2018_rankings = {\n",
    "    '@TBLightning': 3, \n",
    "    '@MapleLeafs':9, \n",
    "    '@NJDevils':13, \n",
    "    '@NHLBruins':8, \n",
    "    '@penguins':6, \n",
    "    '@BlueJacketsNHL':10, \n",
    "    '@NHLFlyers':10, \n",
    "    '@Capitals': 1,\n",
    "    '@Avalanche':10, \n",
    "    '@NHLJets': 4, \n",
    "    '@PredsNHL':5, \n",
    "    '@mnwild':13, \n",
    "    '@LAKings':15, \n",
    "    '@GoldenKnights': 2, \n",
    "    '@AnaheimDucks':15, \n",
    "    '@SanJoseSharks':6\n",
    "}\n",
    "playoff_teams = list(playoff_2018_rankings.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Create a summary by team of the total number of tweets, likes, replies, retweets, engagement per tweet, and proportion of positive tweets (positive_tweet_count/total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_summary = pd.DataFrame(columns=['team', 'tweets', 'ppos', 'likes', 'replies', 'retweets', 'total_engagement'])\n",
    "def summary_table(df, rankings=current_rankings):\n",
    "    row_list = []\n",
    "    for team in team_handles:\n",
    "        if team != '@NHL' and team != '@NHLSeattle_':\n",
    "            total_tweets = df[df['team']==team]['team'].count()\n",
    "            positive_tweets = df[(df['positive']==1) & (df['team']==team)]['positive'].count()\n",
    "            total_likes = df[df['team']==team]['likes'].sum()\n",
    "            total_replies = df[df['team']==team]['replies'].sum()\n",
    "            total_retweets = df[df['team']==team]['retweets'].sum()\n",
    "            total_engagement = total_likes + total_replies + total_retweets\n",
    "\n",
    "            row_list.append({\n",
    "                'team': team,\n",
    "                'tweets': total_tweets,\n",
    "                'ppos': positive_tweets/total_tweets*100,\n",
    "                'total_likes': total_likes,\n",
    "                'total_replies': total_replies,\n",
    "                'total_retweets': total_retweets,\n",
    "                'total_engagement': total_engagement,\n",
    "                'engagement_per_tweet': total_engagement/total_tweets*100,\n",
    "                'ranking': rankings[team]\n",
    "            })\n",
    "    return pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_summary = summary_table(team_tweets)\n",
    "team_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(team_summary.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "<ul>\n",
    "    <li>Negative correlation between ranking & engagement (better performing = higher overall engagement)</li>\n",
    "    <li>Moderate positive correlation between ranking & ppos (portion of tweets that are positive), meaning higher-performing teams have a higher portion of negative tweets</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2018 Playoffs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "playoff_tweets_path = 'data/2018_playoff_tweets.csv'\n",
    "regular_season_path = 'data/2018_regular_season_tweets.csv' # nothing here yet\n",
    "playoffs_start = dt.date(2018,4,11)\n",
    "playoffs_end = dt.date(2018,6,7)\n",
    "\n",
    "if not Path(regular_season_path).exists():\n",
    "    start_2018 = dt.date(2017, 10, 4)\n",
    "    end_2018 = dt.date(2018,4,8)\n",
    "    collect_data(begindate=start_2018, enddate=end_2018, filepath=regular_season_path)\n",
    "if not Path(playoff_tweets_path).exists():\n",
    "    collect_data(begindate=playoffs_start, enddate=playoffs_end, filepath=playoff_tweets_path, handles = playoff_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_tweets = pd.read_csv(playoff_tweets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_polarities_path = 'data/playoff_polarities.csv'\n",
    "if not Path(playoff_polarities_path).exists():\n",
    "    create_polarities(filepath=playoff_tweets_path, polarity_filepath='data/playoff_polarities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoffs_tweets = pd.read_csv(playoff_polarities_path)\n",
    "playoffs_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoffs_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_summary = summary_table(playoffs_tweets).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(playoff_summary.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "<ul>\n",
    "    <li>Like above, negative correlation between ranking and overall engagement: better-performing teams have higher engagement by likes, replies, total tweets, retweets, and engagement per tweet</li>\n",
    "    <li>A moderate, positive correlation exists between ranking and \"ppos\" (portion of positive tweets): higher-ranked teams (i.e. poorer performers) have a higher propertion of positive tweets than those lower in the rankings\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Does the sentiment of a team's tweets correlate to how that team is currently performing?\n",
    "To solve this:\n",
    "<ul>\n",
    "    <li>Choose any team</li>\n",
    "    <li>Get data on the win/lose streak for that team -- I used a Kaggle NHL dataset and filtered for the 2018 playoffs season</li>\n",
    "    <li>Plot the streak as a step function, on the same axis as:</li>\n",
    "    <li>Plot the team's tweet sentiment as a function of time (grouped by days)</li>\n",
    "    <li>Note: to use the same axes for the step- and line plots, I had to normalize the dates in the outcomes dataframe</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = '@NHLBruins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches the team info from the team_info Kaggle NHL games dataset\n",
    "def get_team_info():\n",
    "    team_info = pd.read_csv('data/team_info.csv')\n",
    "    for index, row in team_info.iterrows():\n",
    "        name = row['teamName'].replace(\" \", \"\").lower()\n",
    "        city = row['shortName'].replace(\" \", \"\").lower()\n",
    "        if name == 'predators':\n",
    "            team_info.at[index, 'handle'] = '@PredsNHL'\n",
    "        elif name == 'hurricanes':\n",
    "            team_info.at[index, 'handle'] = '@NHLCanes'\n",
    "        else:\n",
    "            for handle in team_handles:\n",
    "                if name in handle.lower() or city in handle.lower():\n",
    "                    team_info.at[index, 'handle'] = handle\n",
    "    return team_info.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a dataframe of dates & win(1) or lose(0) for a given team, for a given time period\n",
    "def generate_game_outcomes(team, startdate, endate):\n",
    "    startdate = pd.Timestamp(startdate)\n",
    "    endate = pd.Timestamp(endate)\n",
    "    \n",
    "    team_info = get_team_info()\n",
    "    team_id = team_info[team_info['handle']==team]['team_id'].iloc[0]\n",
    "\n",
    "    game_info = pd.read_csv('data/game.csv', parse_dates=True)\n",
    "    game_info['date_time'] = pd.to_datetime(game_info['date_time'], format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    game_info = game_info[(game_info['home_team_id']==team_id) | (game_info['away_team_id']==team_id)]\n",
    "    game_info = game_info[(game_info['date_time'] >= startdate) & (game_info['date_time'] <= endate)]\n",
    "    \n",
    "    for index, row in game_info.iterrows():\n",
    "        if row['home_team_id'] == team_id:\n",
    "            game_info.at[index, 'won'] = row['home_goals'] > row['away_goals']\n",
    "        else:\n",
    "            game_info.at[index, 'won'] = row['away_goals'] > row['home_goals']\n",
    "    game_info.won = game_info.won.astype(int)\n",
    "    return game_info[['date_time', 'won']].sort_values(by=['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_axis_dates(df1, df2):\n",
    "    row_list = []\n",
    "    for date in df1['timestamp']:\n",
    "        if date not in win_by_day['date_time']:\n",
    "            won = 0\n",
    "            for index, row in win_by_day.iterrows():\n",
    "                if date >= row['date_time']:\n",
    "                    won = row['won']\n",
    "            row_list.append({'date_time': date, 'won': won})\n",
    "        normalized_df = df2.append(pd.DataFrame(row_list))\n",
    "    return normalized_df.sort_values(by='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_outcomes = generate_game_outcomes(handle, playoffs_start, playoffs_end)\n",
    "print(\"Game outcomes for team \", handle)\n",
    "game_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_tweets = playoffs_tweets[(playoff_tweets['team']==handle)]\n",
    "print(\"Tweets for team \", handle)\n",
    "handle_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string timestamp to the same format used by the game_outcomes\n",
    "# aggregate average polarity by timestamp grouped by day\n",
    "handle_tweets['timestamp'] = pd.to_datetime(handle_tweets['timestamp'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "polarity_by_day = handle_tweets.groupby(handle_tweets.timestamp.dt.strftime('%m %d %Y'))['polarity'].mean().reset_index(name='polarity').sort_values('timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate winning outcomes by timestamp grouped by day\n",
    "win_by_day = game_outcomes.groupby(game_outcomes.date_time.dt.strftime('%m %d %Y'))['won'].sum().reset_index(name='won').sort_values('date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminated_on = win_by_day.tail(1)['date_time'].iloc[0]\n",
    "print(handle, \" was eliminated on \", eliminated_on)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winning Streak step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('')\n",
    "\n",
    "plt.step(game_outcomes['date_time'], game_outcomes['won'])\n",
    "plt.legend('winning')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_by_day = handle_tweets.groupby(handle_tweets.timestamp.dt.strftime('%m %d %Y'))['likes'].sum().reset_index(name='likes').sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_by_day = normalize_axis_dates(polarity_by_day, win_by_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average sentiment by game outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(win_by_day.date_time, win_by_day.won, label='winning')\n",
    "plt.plot(polarity_by_day.timestamp, polarity_by_day.polarity, label='sentiment')\n",
    "plt.axvline(eliminated_on, color = 'r', label = 'eliminated')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likes per day (scaled) by Game Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(win_by_day.date_time, win_by_day.won, label='winning')\n",
    "plt.plot(likes_by_day.timestamp, np.log(likes_by_day.likes), label='likes')\n",
    "plt.axvline(eliminated_on, color = 'r', label = 'eliminated')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
